{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36ad20f2-8b50-44ea-b532-c4c76da87880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import empty , cat , arange\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import fold , unfold\n",
    "from others.convolution import *\n",
    "from others.activations import *\n",
    "from others.container import *\n",
    "from others.loss import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9efe5c9b-44e1-4950-adce-759a3e6f50aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b158153f-8253-4e5d-bb2b-f96c920ea01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "807f5a79-6714-4902-aad9-30d963ff91e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f910c672c20>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "daf55169-ccb1-4b5d-b66b-8a1375d50047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loss(loss, ref_loss):\n",
    "    for loop in range(10):\n",
    "        x = torch.randn((2 , 3 , 32 , 32), requires_grad=True)\n",
    "        y = torch.randn((2 , 3 , 32 , 32))\n",
    "        l1 = loss(x,y)\n",
    "        l2 = ref_loss(x,y) \n",
    "    \n",
    "        torch.testing.assert_allclose( l1, l2)\n",
    "        \n",
    "        grad_1 = loss.backward()\n",
    "        l2.backward()\n",
    "        grad_2 = x.grad\n",
    "    \n",
    "        torch.testing.assert_allclose(grad_1, grad_2)\n",
    "    \n",
    "    x = torch.randn((1 , 3 , 32 , 32),requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "16f4436f-08ff-40d3-bd2e-ba4c634bbccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss(MSE(),F.mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a6dde807-dcaf-45dd-be47-82d268686eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_activations(act, ref_act):\n",
    "    mse = MSE()\n",
    "    for loop in range(10):\n",
    "        x = torch.randn((2 , 1 , 3 , 3), requires_grad=True)\n",
    "        y = torch.randn((2 , 1 , 3 , 3))\n",
    "        \n",
    "        x1 = act(x)\n",
    "        x2 = ref_act(x)\n",
    "        \n",
    "        l1 = mse(x1,y)\n",
    "        l2 = F.mse_loss(x2,y)\n",
    "        torch.testing.assert_allclose( l1, l2)\n",
    "        \n",
    "        grad_1 = act.backward(mse.backward())\n",
    "        l2.backward()\n",
    "        grad_2 = x.grad\n",
    "    \n",
    "        torch.testing.assert_allclose(grad_1, grad_2)\n",
    "        \n",
    "    \n",
    "    \n",
    "    x = torch.randn((1 , 3 , 32 , 32),requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "64fdf2e7-d1ea-4a7d-8b37-15cc52c6819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_activations(ReLU(), F.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aad63771-1f43-4d6c-bfc2-05420c1b9818",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_activations(Sigmoid(), torch.sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6d8cb3c9-7dcc-43d8-a491-b4e56073f6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_block(block, ref_block):\n",
    "    mse = MSE()\n",
    "    for loop in range(10):\n",
    "        x = torch.randn((2 , 3 , 32 , 32), requires_grad=True)\n",
    "        y = torch.randn((2 , 3 , 32 , 32))\n",
    "        \n",
    "        x1 = block(x)\n",
    "        x2 = ref_block(x)\n",
    "        torch.testing.assert_allclose( x1, x2)\n",
    "        \n",
    "        y = torch.randn(x1.shape)\n",
    "        \n",
    "        l1 = mse(x1,y)\n",
    "        l2 = F.mse_loss(x2,y)\n",
    "        torch.testing.assert_allclose( l1, l2)\n",
    "        \n",
    "        grad_1 = block.backward(mse.backward())\n",
    "        l2.backward()\n",
    "        grad_2 = x.grad\n",
    "    \n",
    "        torch.testing.assert_allclose(grad_1, grad_2)\n",
    "      \n",
    "        \n",
    "    \n",
    "     \n",
    "    \n",
    "   \n",
    "   \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c07a241e-677d-4fe2-913f-bc28fe4637ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = 3\n",
    "out_channels=3\n",
    "kernel_size=(2, 2)\n",
    "stride=1\n",
    "\n",
    "conv = Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride)\n",
    "conv_ref = lambda x : F.conv2d(x, conv.weight, conv.bias) \n",
    "test_block(conv, conv_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a5766493-f0c6-445c-a61d-c5af7ee9f0e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TransposeConv2d' object has no attribute 'bais'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [113]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m kernel_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      4\u001b[0m stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 7\u001b[0m trans_conv \u001b[38;5;241m=\u001b[39m \u001b[43mUpsampling\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m trans_conv_ref \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x : F\u001b[38;5;241m.\u001b[39mconv_transpose2d(x, trans_conv\u001b[38;5;241m.\u001b[39mweight, bias\u001b[38;5;241m=\u001b[39mtrans_conv\u001b[38;5;241m.\u001b[39mbias)\n\u001b[1;32m      9\u001b[0m test_block(trans_conv, trans_conv_ref)\n",
      "File \u001b[0;32m~/Bureau/noise2noise/Proj/Miniproject_2/others/convolution.py:199\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation)\u001b[0m\n\u001b[1;32m    197\u001b[0m     self.transposedConv2d = TransposeConv2d(in_channels, out_channels, kernel_size, stride, padding, dilation)\n\u001b[1;32m    198\u001b[0m     self.weight = self.transposedConv2d.weight\n\u001b[0;32m--> 199\u001b[0m     self.bais = self.transposedConv2d.bais\n\u001b[1;32m    200\u001b[0m \n\u001b[1;32m    201\u001b[0m def forward(self, input_):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TransposeConv2d' object has no attribute 'bais'"
     ]
    }
   ],
   "source": [
    "in_channels = 3\n",
    "out_channels=3\n",
    "kernel_size=(2, 2)\n",
    "stride=1\n",
    "\n",
    "\n",
    "trans_conv = Upsampling(in_channels, out_channels, kernel_size, stride=stride)\n",
    "trans_conv_ref = lambda x : F.conv_transpose2d(x, trans_conv.weight, bias=trans_conv.bias)\n",
    "test_block(trans_conv, trans_conv_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7899d268-4482-455b-823f-c21d84c24dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mUpsampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mout_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdilation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m      Upsampling module (underlying is TransposeConv2d)\n",
       "\u001b[0;31mInit docstring:\u001b[0m Upsampling constructor\n",
       "\u001b[0;31mFile:\u001b[0m           ~/Bureau/noise2noise/Proj/Miniproject_2/others/convolution.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Upsampling??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790c0d6e-cbd8-4c33-b3af-885da18c5547",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
