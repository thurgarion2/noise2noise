{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54243c74-7916-4ae4-b2b1-85507b9949c3",
   "metadata": {
    "id": "54243c74-7916-4ae4-b2b1-85507b9949c3"
   },
   "outputs": [],
   "source": [
    "#default_exp architectures\n",
    "#all_slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358b435e-860e-4fa3-adc2-11a10627c999",
   "metadata": {
    "id": "358b435e-860e-4fa3-adc2-11a10627c999"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e3e182-b0ea-4976-b947-61e8b086c8d6",
   "metadata": {
    "id": "50e3e182-b0ea-4976-b947-61e8b086c8d6",
    "outputId": "c3f83e78-fc11-4c1d-d442-b1007722bead"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_architecture_to_test.ipynb.\n",
      "Converted 00_augmentation.ipynb.\n",
      "Converted 00_baseline.ipynb.\n",
      "Converted 00_helpers.ipynb.\n",
      "Converted 00_training.ipynb.\n",
      "Converted 00_unet.ipynb.\n",
      "Converted 00_unet_resnet.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#run to export library\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9322e2d3-51e7-45b1-859f-0d1768c1cbc3",
   "metadata": {
    "id": "9322e2d3-51e7-45b1-859f-0d1768c1cbc3"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e246f7df-5a35-4fd0-a636-4a2ff5429d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from noise2noise.helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaef5c13-7f4c-4134-b109-8c86333b0668",
   "metadata": {
    "id": "aaef5c13-7f4c-4134-b109-8c86333b0668"
   },
   "source": [
    "# Architectures\n",
    "\n",
    "> Architectures we compare in the first part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c693a2f1-507d-45f1-9035-5825fb3b2d40",
   "metadata": {
    "id": "c693a2f1-507d-45f1-9035-5825fb3b2d40"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class ResNetBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels, kernel_size=(3, 3), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channels, channels, kernel_size=(3, 3), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(channels))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return F.relu(self.layers(x)+x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00861f88-f71c-4e1e-829e-aa1fbfbb9034",
   "metadata": {
    "id": "00861f88-f71c-4e1e-829e-aa1fbfbb9034",
    "outputId": "f5e5ae04-5a4e-453a-9a5f-56d90a48fb05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 32, 32])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_imgs_1 , noisy_imgs_2 = load_images()\n",
    "img = to_float_image(noisy_imgs_1[:2])\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e77e6dca-1088-4ea4-be3e-95509f101895",
   "metadata": {
    "id": "e77e6dca-1088-4ea4-be3e-95509f101895",
    "outputId": "44a42b5b-f606-478b-d95f-1be2010303c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 32, 32])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block = ResNetBlock(3)\n",
    "block(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5562bc70-2e98-4685-b9cd-a2832fc08951",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ConvNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        channels = [(3,64),(64,64),(64,64),(64,128),(128,128),(128,256),(256,256),(256,3)]\n",
    "        self.layers = nn.Sequential(*[nn.Sequential(\n",
    "            nn.Conv2d(ch_in, ch_out, kernel_size=(3, 3), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(ch_out),\n",
    "            nn.ReLU(inplace=True)) for ch_in, ch_out in channels\n",
    "        ])\n",
    "        self.last_layer = nn.Conv2d(3, 3, kernel_size=(3, 3), padding=(1, 1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return self.last_layer(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "973a6ece-02c4-45b5-ab52-7359cb30f52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 32, 32])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConvNet()\n",
    "model(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3934e8af-7af6-4ea4-a42a-14a9bf3c4cc7",
   "metadata": {
    "id": "3934e8af-7af6-4ea4-a42a-14a9bf3c4cc7"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.block_64 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=(3, 3), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            ResNetBlock(64)\n",
    "        )\n",
    "        \n",
    "        self.block_128 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=(3, 3), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            ResNetBlock(128),\n",
    "            ResNetBlock(128)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.block_256 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=(3, 3), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            ResNetBlock(256)\n",
    "        )\n",
    "        \n",
    "        self.last_layer = nn.Conv2d(256, 3, kernel_size=3, padding=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.block_64(x)\n",
    "        x = self.block_128(x)\n",
    "        x = self.block_256(x)\n",
    "        return self.last_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7c181a1-2e63-4b68-97af-50a50299b137",
   "metadata": {
    "id": "e7c181a1-2e63-4b68-97af-50a50299b137",
    "outputId": "65e68e44-9bcf-4760-a5d8-110841431ca4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 32, 32])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet()\n",
    "model(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49e235f-379f-4711-afbf-b9d03372e8ae",
   "metadata": {
    "id": "f49e235f-379f-4711-afbf-b9d03372e8ae"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        \n",
    "        channels = [(3,64), (64,128), (128,256)]\n",
    "        self.encoder = nn.ModuleList([nn.Sequential(nn.Conv2d(ch_in, ch_out, kernel_size=3, padding=1),\n",
    "                                                    nn.BatchNorm2d(ch_out),\n",
    "                                                    ResNetBlock(ch_out)) for ch_in, ch_out in channels])\n",
    "        self.down = nn.MaxPool2d(2, stride=2)\n",
    "        self.decoder = self.make_decoder_from_encoder(self.encoder)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.middle = ResNetBlock(256)\n",
    "        self.last_layer = nn.Conv2d(3, 3, kernel_size=3, padding=1)\n",
    "        \n",
    "        \n",
    "    def make_decoder_from_encoder(self, encoder):\n",
    "        decoder = []\n",
    "        \n",
    "        x = torch.zeros((2,3,32,32))\n",
    "        \n",
    "        for l in encoder:\n",
    "            last_channels = x.size(1)\n",
    "            x = l(x)\n",
    "            channels = x.size(1)\n",
    "            decoder.append(nn.Sequential(ResNetBlock(channels),\n",
    "                                             nn.Conv2d(channels, last_channels, kernel_size=3, padding=1),\n",
    "                                             nn.BatchNorm2d(last_channels)))\n",
    "        \n",
    "        decoder.reverse()\n",
    "        return nn.ModuleList(decoder)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        intermediary_x = []\n",
    "        \n",
    "        \n",
    "        for l in self.encoder:\n",
    "            x = l(x)\n",
    "            intermediary_x.append(x)\n",
    "            x = self.down(x)\n",
    "            \n",
    "        \n",
    "        x = self.middle(x)\n",
    "        intermediary_x.reverse()\n",
    "        \n",
    "        for l, z in zip(self.decoder, intermediary_x):\n",
    "            x = F.interpolate(x,z.shape[2:])\n",
    "            x = l(x+z)\n",
    "          \n",
    "            \n",
    "        return self.last_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd4c6f7-3bb0-49eb-ba54-3b69c5cc3953",
   "metadata": {
    "id": "cbd4c6f7-3bb0-49eb-ba54-3b69c5cc3953",
    "outputId": "f9ccc4b7-f3c7-452d-f478-bae694e9d63b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 32, 32])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Unet()\n",
    "model(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71a2a0c3-e9fa-4dc4-b36b-710b1612fef9",
   "metadata": {
    "id": "71a2a0c3-e9fa-4dc4-b36b-710b1612fef9"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class UnetWithConcat(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        \n",
    "        channels = [(3,64), (64,128), (128,256)]\n",
    "        self.encoder = nn.ModuleList([nn.Sequential(nn.Conv2d(ch_in, ch_out, kernel_size=3, padding=1),\n",
    "                                                    nn.BatchNorm2d(ch_out),\n",
    "                                                    ResNetBlock(ch_out)) for ch_in, ch_out in channels])\n",
    "        self.down = nn.MaxPool2d(2, stride=2)\n",
    "        self.decoder = self.make_decoder_from_encoder(self.encoder)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.middle = ResNetBlock(256)\n",
    "        self.last_layer = nn.Conv2d(6, 3, kernel_size=3, padding=1)\n",
    "        \n",
    "        \n",
    "    def make_decoder_from_encoder(self, encoder):\n",
    "        decoder = []\n",
    "        \n",
    "        x = torch.zeros((2,3,32,32))\n",
    "        \n",
    "        for l in encoder:\n",
    "            last_channels = x.size(1)\n",
    "            x = l(x)\n",
    "            channels = x.size(1)\n",
    "            decoder.append(nn.Sequential(ResNetBlock(channels),\n",
    "                                             nn.Conv2d(channels, last_channels, kernel_size=3, padding=1),\n",
    "                                             nn.BatchNorm2d(last_channels)))\n",
    "        \n",
    "        decoder.reverse()\n",
    "        return nn.ModuleList(decoder)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        intermediary_x = []\n",
    "        img = x\n",
    "        \n",
    "        for l in self.encoder:\n",
    "            x = l(x)\n",
    "            intermediary_x.append(x)\n",
    "            x = self.down(x)\n",
    "            \n",
    "        \n",
    "        x = self.middle(x)\n",
    "        intermediary_x.reverse()\n",
    "        \n",
    "        for l, z in zip(self.decoder, intermediary_x):\n",
    "            x = F.interpolate(x,z.shape[2:])\n",
    "            x = l(x+z)\n",
    "          \n",
    "            \n",
    "        return torch.sigmoid(self.last_layer(torch.cat((x, img), 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e929ff6c-12d6-4195-8614-1737028b9904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 32, 32])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = UnetWithSigmoid()\n",
    "model(img).shape"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "00_architecture_to_test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
